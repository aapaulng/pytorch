{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install http://download.pytorch.org/whl/cu90/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0.post4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 10222\n",
      "10357 10357\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "# NUM_CLASSES = 16\n",
    "root_dir = '/home/paul/share/dog/'\n",
    "labels = pd.read_csv(join(root_dir, 'labels.csv'))\n",
    "sample_submission = pd.read_csv(join(root_dir, 'sample_submission.csv'))\n",
    "print(len(listdir(join(root_dir, 'train'))), len(labels))\n",
    "print(len(listdir(join(root_dir, 'test'))), len(sample_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e       0.008333      0.008333   \n",
       "1  00102ee9d8eb90812350685311fe5890       0.008333      0.008333   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce       0.008333      0.008333   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1       0.008333      0.008333   \n",
       "4  001a5f3114548acdefa3d4da05474c2e       0.008333      0.008333   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0             0.008333  0.008333                        0.008333     0.008333   \n",
       "1             0.008333  0.008333                        0.008333     0.008333   \n",
       "2             0.008333  0.008333                        0.008333     0.008333   \n",
       "3             0.008333  0.008333                        0.008333     0.008333   \n",
       "4             0.008333  0.008333                        0.008333     0.008333   \n",
       "\n",
       "   australian_terrier   basenji    basset        ...          toy_poodle  \\\n",
       "0            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "1            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "2            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "3            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "4            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "\n",
       "   toy_terrier    vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "1     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "2     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "3     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "4     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                     0.008333  0.008333                 0.008333   \n",
       "1                     0.008333  0.008333                 0.008333   \n",
       "2                     0.008333  0.008333                 0.008333   \n",
       "3                     0.008333  0.008333                 0.008333   \n",
       "4                     0.008333  0.008333                 0.008333   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0           0.008333  \n",
       "1           0.008333  \n",
       "2           0.008333  \n",
       "3           0.008333  \n",
       "4           0.008333  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200 1022 10357\n"
     ]
    }
   ],
   "source": [
    "# selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "# labels = labels[labels['breed'].isin(selected_breed_list)]\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels['class'] = le.fit_transform(labels['breed'])\n",
    "# labels['target'] = 1\n",
    "# labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "\n",
    "train = labels.sample(frac=0.9)\n",
    "valid = labels[~labels['id'].isin(train['id'])]\n",
    "test = pd.DataFrame(sample_submission['id'])\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, train = True, transform=None):\n",
    "        self.train = train\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = '{}.jpg'.format(self.labels.iloc[idx, 0])\n",
    "        fullpath = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullpath)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.train:\n",
    "            labels = self.labels.iloc[idx, 2]\n",
    "            return [image, labels]\n",
    "        else:\n",
    "            ids = self.labels.iloc[idx, 0]\n",
    "            return image, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# ds_trans = transforms.Compose([transforms.Scale(224),\n",
    "#                                transforms.CenterCrop(224),\n",
    "#                                transforms.ToTensor(),\n",
    "#                                normalize])\n",
    "\n",
    "ds_trans = transforms.Compose([transforms.Scale(224),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.RandomSizedCrop(224), \n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               transforms.ToTensor(),\n",
    "                               normalize])\n",
    "\n",
    "dv_trans = transforms.Compose([transforms.Scale(256),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.ToTensor(),\n",
    "                               normalize])\n",
    "\n",
    "train_ds = DogsDataset(train, join(root_dir,'train'), train=True, transform=ds_trans)\n",
    "valid_ds = DogsDataset(valid, join(root_dir,'train'), train=True, transform=dv_trans)\n",
    "test_ds = DogsDataset(test, join(root_dir,'test'), train=False, transform=dv_trans)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(axis, inp):\n",
    "    \"\"\"Denormalize and show\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    axis.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label = next(iter(train_dl))\n",
    "# print(img.size(), label.size())\n",
    "# fig = plt.figure(1, figsize=(16, 4))\n",
    "# grid = ImageGrid(fig, 111, nrows_ncols=(1, 4), axes_pad=0.05)    \n",
    "# for i in range(img.size()[0]):\n",
    "#     ax = grid[i]\n",
    "#     imshow(ax, img[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "inputs, labels = next(iter(train_dl))\n",
    "if use_gpu:\n",
    "    resnet = resnet.cuda()\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())   \n",
    "else:\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "outputs = resnet(inputs)\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'train': len(dataloders['train'].dataset), \n",
    "                     'valid': len(dataloders['valid'].dataset)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "#                 print(outputs, labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                \n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n",
    "              'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                epoch, num_epochs - 1,\n",
    "                train_epoch_loss, train_epoch_acc, \n",
    "                valid_epoch_loss, valid_epoch_acc))\n",
    "            \n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Time for 1 epoch: {:.4f})'.format(time.time()-since))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 120 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, 120)\n",
    "# if use_gpu:\n",
    "#     resnet = resnet.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "dloaders = {'train':train_dl, 'valid':valid_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/24] train loss: 0.7640 acc: 0.3237 valid loss: 0.2474 acc: 0.7241\n",
      "Epoch [1/24] train loss: 0.4092 acc: 0.5942 valid loss: 0.1972 acc: 0.7583\n",
      "Epoch [2/24] train loss: 0.3269 acc: 0.6590 valid loss: 0.1613 acc: 0.8170\n",
      "Epoch [3/24] train loss: 0.2918 acc: 0.6822 valid loss: 0.1588 acc: 0.7965\n",
      "Epoch [4/24] train loss: 0.2666 acc: 0.7078 valid loss: 0.1542 acc: 0.8268\n",
      "Epoch [5/24] train loss: 0.2529 acc: 0.7177 valid loss: 0.1643 acc: 0.8023\n",
      "Epoch [6/24] train loss: 0.2402 acc: 0.7246 valid loss: 0.1653 acc: 0.7965\n",
      "Epoch [7/24] train loss: 0.2087 acc: 0.7710 valid loss: 0.1586 acc: 0.8141\n",
      "Epoch [8/24] train loss: 0.2038 acc: 0.7798 valid loss: 0.1504 acc: 0.8209\n",
      "Epoch [9/24] train loss: 0.2069 acc: 0.7751 valid loss: 0.1559 acc: 0.8190\n",
      "Epoch [10/24] train loss: 0.2068 acc: 0.7700 valid loss: 0.1516 acc: 0.8170\n",
      "Epoch [11/24] train loss: 0.2022 acc: 0.7813 valid loss: 0.1581 acc: 0.8112\n",
      "Epoch [12/24] train loss: 0.2024 acc: 0.7812 valid loss: 0.1560 acc: 0.8121\n",
      "Epoch [13/24] train loss: 0.2033 acc: 0.7779 valid loss: 0.1497 acc: 0.8278\n",
      "Epoch [14/24] train loss: 0.2015 acc: 0.7768 valid loss: 0.1479 acc: 0.8209\n",
      "Epoch [15/24] train loss: 0.1976 acc: 0.7811 valid loss: 0.1567 acc: 0.8151\n",
      "Epoch [16/24] train loss: 0.1939 acc: 0.7927 valid loss: 0.1447 acc: 0.8160\n",
      "Epoch [17/24] train loss: 0.1999 acc: 0.7860 valid loss: 0.1508 acc: 0.8200\n",
      "Epoch [18/24] train loss: 0.1929 acc: 0.7927 valid loss: 0.1532 acc: 0.8190\n",
      "Epoch [19/24] train loss: 0.1920 acc: 0.7935 valid loss: 0.1493 acc: 0.8072\n",
      "Epoch [20/24] train loss: 0.1979 acc: 0.7863 valid loss: 0.1525 acc: 0.8141\n",
      "Epoch [21/24] train loss: 0.1992 acc: 0.7904 valid loss: 0.1528 acc: 0.8170\n",
      "Epoch [22/24] train loss: 0.1970 acc: 0.7861 valid loss: 0.1490 acc: 0.8151\n",
      "Epoch [23/24] train loss: 0.1978 acc: 0.7886 valid loss: 0.1449 acc: 0.8278\n",
      "Epoch [24/24] train loss: 0.1999 acc: 0.7853 valid loss: 0.1484 acc: 0.8249\n",
      "Best val Acc: 0.827789\n",
      "Training time:  77.039712 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = train_model(dloaders, resnet, criterion, optimizer, exp_lr_scheduler, num_epochs=1)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'affenpinscher', 'afghan_hound', 'african_hunting_dog',\n",
       "       'airedale', 'american_staffordshire_terrier', 'appenzeller',\n",
       "       'australian_terrier', 'basenji', 'basset',\n",
       "       ...\n",
       "       'toy_poodle', 'toy_terrier', 'vizsla', 'walker_hound', 'weimaraner',\n",
       "       'welsh_springer_spaniel', 'west_highland_white_terrier', 'whippet',\n",
       "       'wire-haired_fox_terrier', 'yorkshire_terrier'],\n",
       "      dtype='object', length=121)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    res_list = torch.FloatTensor().cuda()\n",
    "else:\n",
    "    res_list = torch.FloatTensor()\n",
    "\n",
    "ids_list = []\n",
    "for i, data in enumerate(test_dl):\n",
    "    images, ids = data\n",
    "#     images = Variable(images)\n",
    "    if use_gpu:\n",
    "        images = Variable(images.cuda())\n",
    "    else:\n",
    "        images = Variable(images)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    \n",
    "    outputs_softmax = F.softmax(outputs)\n",
    "    res_list = torch.cat((res_list, outputs_softmax.data),0)\n",
    "    ids_list.append(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = pd.DataFrame(list(res_list))\n",
    "submission_file = pd.concat([sample_submission['id'],submission_file], axis=1)\n",
    "submission_file.columns = list(sample_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv('/home/paul/share/dog/submission_file_resnet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
